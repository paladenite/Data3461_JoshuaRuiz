{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49cf8381",
   "metadata": {
    "id": "49cf8381"
   },
   "source": [
    "# Lab 6\n",
    "\n",
    "Scikit learn provides a large variety of algorithms for some common Machine Learning tasks, such as:\n",
    "\n",
    "* Classification\n",
    "* Regression\n",
    "* Clustering\n",
    "* Feature Selection\n",
    "* Anomaly Detection\n",
    "\n",
    "It also provides some datasets that you can use to test these algorithms:\n",
    "\n",
    "* Classification Datasets:\n",
    "    * Breast cancer wisconsin\n",
    "    * Iris plants (3-classes)\n",
    "    * Optical recognition of handwritten digits (10-classes)\n",
    "    * Wine (n-classes)\n",
    "\n",
    "* Regression Datasets:\n",
    "    * Boston house prices\n",
    "    * Diabetes\n",
    "    * Linnerrud (multiple regression)\n",
    "    * California Housing\n",
    "\n",
    "* Image:\n",
    "    * The Olivetti faces\n",
    "    * The Labeled Faces in the Wild face recognition\n",
    "    * Forest covertypes\n",
    "\n",
    "* NLP:\n",
    "    * News group\n",
    "    * Reuters Corpus Volume I\n",
    "\n",
    "* Other:\n",
    "    * Kddcup 99- Intrusion Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e3b6e9",
   "metadata": {
    "id": "d4e3b6e9"
   },
   "source": [
    "## Exercises\n",
    "\n",
    "1. Use the full [Kddcup](http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html) dataset to compare classification performance of 3 different classifiers.\n",
    "    * Separate the data into train, validation, and test.\n",
    "    * Use accuracy as the metric for assessing performance.\n",
    "    * For each classifier, identify the hyperparameters. Perform optimization over at least 2 hyperparameters.   \n",
    "    * Compare the performance of the optimal configuration of the classifiers.\n",
    "\n",
    "2. Pick the best algorithm in question 1. Create an ensemble of at least 25 models, and use them for the classification task. Identify the top and bottom 10% of the data in terms of uncertainty of the decision.\n",
    "\n",
    "3. Use 2 different feature selection algorithm to identify the 10 most important features for the task in question 1. Retrain classifiers in question 1 with just this subset of features and compare performance.\n",
    "\n",
    "4. Use the same data, removing the labels, and compare performance of 3 different clustering algorithms. Can you find clusters for each of the classes in question 1?\n",
    "\n",
    "5. Can you identify any clusters within the top/botton 10% identified in 2. What are their characteristics?\n",
    "\n",
    "6. Use the \"SA\" dataset to compare the performance of 3 different anomaly detection algorithms.\n",
    "\n",
    "7. Create a subsample of 250 datapoints, redo question 6, using Leave-one-out as the method of evaluation.\n",
    "\n",
    "8. Use the feature selection algorithm to identify the 5 most important features for the task in question 6, for each algorithm. Does the anomaly detection improve using less features?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef18662c",
   "metadata": {
    "id": "ef18662c"
   },
   "source": [
    "## Quick look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f1c631a",
   "metadata": {
    "id": "9f1c631a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, silhouette_score\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE, SelectFromModel\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.datasets import fetch_kddcup99\n",
    "D=fetch_kddcup99()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d561eff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7d561eff",
    "outputId": "d1d052bd-f754-4b6a-de31-329161c2e6e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR', 'data', 'feature_names', 'frame', 'target', 'target_names']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "875d2d16",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "875d2d16",
    "outputId": "980a2ff9-d1d7-4024-96e3-3840c06ce2e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _kddcup99_dataset:\n",
      "\n",
      "Kddcup 99 dataset\n",
      "-----------------\n",
      "\n",
      "The KDD Cup '99 dataset was created by processing the tcpdump portions\n",
      "of the 1998 DARPA Intrusion Detection System (IDS) Evaluation dataset,\n",
      "created by MIT Lincoln Lab [2]_. The artificial data (described on the `dataset's\n",
      "homepage <https://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html>`_) was\n",
      "generated using a closed network and hand-injected attacks to produce a\n",
      "large number of different types of attack with normal activity in the\n",
      "background. As the initial goal was to produce a large training set for\n",
      "supervised learning algorithms, there is a large proportion (80.1%) of\n",
      "abnormal data which is unrealistic in real world, and inappropriate for\n",
      "unsupervised anomaly detection which aims at detecting 'abnormal' data, i.e.:\n",
      "\n",
      "* qualitatively different from normal data\n",
      "* in large minority among the observations.\n",
      "\n",
      "We thus transform the KDD Data set into two different data sets: SA and SF.\n",
      "\n",
      "* SA is obtained by simply selecting all the normal data, and a small\n",
      "  proportion of abnormal data to gives an anomaly proportion of 1%.\n",
      "\n",
      "* SF is obtained as in [3]_\n",
      "  by simply picking up the data whose attribute logged_in is positive, thus\n",
      "  focusing on the intrusion attack, which gives a proportion of 0.3% of\n",
      "  attack.\n",
      "\n",
      "* http and smtp are two subsets of SF corresponding with third feature\n",
      "  equal to 'http' (resp. to 'smtp').\n",
      "\n",
      "General KDD structure:\n",
      "\n",
      "================      ==========================================\n",
      "Samples total         4898431\n",
      "Dimensionality        41\n",
      "Features              discrete (int) or continuous (float)\n",
      "Targets               str, 'normal.' or name of the anomaly type\n",
      "================      ==========================================\n",
      "\n",
      "SA structure:\n",
      "\n",
      "================      ==========================================\n",
      "Samples total         976158\n",
      "Dimensionality        41\n",
      "Features              discrete (int) or continuous (float)\n",
      "Targets               str, 'normal.' or name of the anomaly type\n",
      "================      ==========================================\n",
      "\n",
      "SF structure:\n",
      "\n",
      "================      ==========================================\n",
      "Samples total         699691\n",
      "Dimensionality        4\n",
      "Features              discrete (int) or continuous (float)\n",
      "Targets               str, 'normal.' or name of the anomaly type\n",
      "================      ==========================================\n",
      "\n",
      "http structure:\n",
      "\n",
      "================      ==========================================\n",
      "Samples total         619052\n",
      "Dimensionality        3\n",
      "Features              discrete (int) or continuous (float)\n",
      "Targets               str, 'normal.' or name of the anomaly type\n",
      "================      ==========================================\n",
      "\n",
      "smtp structure:\n",
      "\n",
      "================      ==========================================\n",
      "Samples total         95373\n",
      "Dimensionality        3\n",
      "Features              discrete (int) or continuous (float)\n",
      "Targets               str, 'normal.' or name of the anomaly type\n",
      "================      ==========================================\n",
      "\n",
      ":func:`sklearn.datasets.fetch_kddcup99` will load the kddcup99 dataset; it\n",
      "returns a dictionary-like object with the feature matrix in the ``data`` member\n",
      "and the target values in ``target``. The \"as_frame\" optional argument converts\n",
      "``data`` into a pandas DataFrame and ``target`` into a pandas Series. The\n",
      "dataset will be downloaded from the web if necessary.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "    .. [2] Analysis and Results of the 1999 DARPA Off-Line Intrusion\n",
      "           Detection Evaluation, Richard Lippmann, Joshua W. Haines,\n",
      "           David J. Fried, Jonathan Korba, Kumar Das.\n",
      "\n",
      "    .. [3] K. Yamanishi, J.-I. Takeuchi, G. Williams, and P. Milne. Online\n",
      "           unsupervised outlier detection using finite mixtures with\n",
      "           discounting learning algorithms. In Proceedings of the sixth\n",
      "           ACM SIGKDD international conference on Knowledge discovery\n",
      "           and data mining, pages 320-324. ACM Press, 2000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(D[\"DESCR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3c3c5b8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f3c3c5b8",
    "outputId": "918b168f-b292-4700-cb6b-9780833a17f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR', 'data', 'feature_names', 'frame', 'target', 'target_names']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cef559d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4cef559d",
    "outputId": "ea0b05d5-76a5-40e2-ea48-1764602b0486"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'back.', b'buffer_overflow.', b'ftp_write.', b'guess_passwd.',\n",
       "       b'imap.', b'ipsweep.', b'land.', b'loadmodule.', b'multihop.',\n",
       "       b'neptune.', b'nmap.', b'normal.', b'perl.', b'phf.', b'pod.',\n",
       "       b'portsweep.', b'rootkit.', b'satan.', b'smurf.', b'spy.',\n",
       "       b'teardrop.', b'warezclient.', b'warezmaster.'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(D[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ed0289b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ed0289b",
    "outputId": "02dc57eb-470e-4984-b8e0-ec1d10748633"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(D[\"target\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aff034ea",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aff034ea",
    "outputId": "cf1e9d4b-9f69-498e-e001-6d3077697d3a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['duration',\n",
       " 'protocol_type',\n",
       " 'service',\n",
       " 'flag',\n",
       " 'src_bytes',\n",
       " 'dst_bytes',\n",
       " 'land',\n",
       " 'wrong_fragment',\n",
       " 'urgent',\n",
       " 'hot',\n",
       " 'num_failed_logins',\n",
       " 'logged_in',\n",
       " 'num_compromised',\n",
       " 'root_shell',\n",
       " 'su_attempted',\n",
       " 'num_root',\n",
       " 'num_file_creations',\n",
       " 'num_shells',\n",
       " 'num_access_files',\n",
       " 'num_outbound_cmds',\n",
       " 'is_host_login',\n",
       " 'is_guest_login',\n",
       " 'count',\n",
       " 'srv_count',\n",
       " 'serror_rate',\n",
       " 'srv_serror_rate',\n",
       " 'rerror_rate',\n",
       " 'srv_rerror_rate',\n",
       " 'same_srv_rate',\n",
       " 'diff_srv_rate',\n",
       " 'srv_diff_host_rate',\n",
       " 'dst_host_count',\n",
       " 'dst_host_srv_count',\n",
       " 'dst_host_same_srv_rate',\n",
       " 'dst_host_diff_srv_rate',\n",
       " 'dst_host_same_src_port_rate',\n",
       " 'dst_host_srv_diff_host_rate',\n",
       " 'dst_host_serror_rate',\n",
       " 'dst_host_srv_serror_rate',\n",
       " 'dst_host_rerror_rate',\n",
       " 'dst_host_srv_rerror_rate']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D[\"feature_names\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77b2222",
   "metadata": {
    "id": "b77b2222"
   },
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c31eccfb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 256
    },
    "id": "c31eccfb",
    "outputId": "8b88b82f-df5d-4196-b019-c7a21b935833"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b'tcp'</td>\n",
       "      <td>b'http'</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>181</td>\n",
       "      <td>5450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'normal.'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>b'tcp'</td>\n",
       "      <td>b'http'</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>239</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'normal.'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>b'tcp'</td>\n",
       "      <td>b'http'</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>235</td>\n",
       "      <td>1337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'normal.'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>b'tcp'</td>\n",
       "      <td>b'http'</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>219</td>\n",
       "      <td>1337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'normal.'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>b'tcp'</td>\n",
       "      <td>b'http'</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>217</td>\n",
       "      <td>2032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'normal.'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  duration protocol_type  service   flag src_bytes dst_bytes land  \\\n",
       "0        0        b'tcp'  b'http'  b'SF'       181      5450    0   \n",
       "1        0        b'tcp'  b'http'  b'SF'       239       486    0   \n",
       "2        0        b'tcp'  b'http'  b'SF'       235      1337    0   \n",
       "3        0        b'tcp'  b'http'  b'SF'       219      1337    0   \n",
       "4        0        b'tcp'  b'http'  b'SF'       217      2032    0   \n",
       "\n",
       "  wrong_fragment urgent hot  ... dst_host_srv_count dst_host_same_srv_rate  \\\n",
       "0              0      0   0  ...                  9                    1.0   \n",
       "1              0      0   0  ...                 19                    1.0   \n",
       "2              0      0   0  ...                 29                    1.0   \n",
       "3              0      0   0  ...                 39                    1.0   \n",
       "4              0      0   0  ...                 49                    1.0   \n",
       "\n",
       "  dst_host_diff_srv_rate dst_host_same_src_port_rate  \\\n",
       "0                    0.0                        0.11   \n",
       "1                    0.0                        0.05   \n",
       "2                    0.0                        0.03   \n",
       "3                    0.0                        0.03   \n",
       "4                    0.0                        0.02   \n",
       "\n",
       "  dst_host_srv_diff_host_rate dst_host_serror_rate dst_host_srv_serror_rate  \\\n",
       "0                         0.0                  0.0                      0.0   \n",
       "1                         0.0                  0.0                      0.0   \n",
       "2                         0.0                  0.0                      0.0   \n",
       "3                         0.0                  0.0                      0.0   \n",
       "4                         0.0                  0.0                      0.0   \n",
       "\n",
       "  dst_host_rerror_rate dst_host_srv_rerror_rate      target  \n",
       "0                  0.0                      0.0  b'normal.'  \n",
       "1                  0.0                      0.0  b'normal.'  \n",
       "2                  0.0                      0.0  b'normal.'  \n",
       "3                  0.0                      0.0  b'normal.'  \n",
       "4                  0.0                      0.0  b'normal.'  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(D.data, columns=D.feature_names)\n",
    "df[\"target\"]=D.target\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7acdd2f",
   "metadata": {
    "id": "c7acdd2f"
   },
   "outputs": [],
   "source": [
    "continuous_columns=[\"duration\", \"src_bytes\", \"dst_bytes\", \"wrong_fragment\", \"urgent\", \"hot\",\n",
    "    \"num_failed_logins\", \"num_compromised\", \"root_shell\", \"su_attempted\", \"num_root\",\n",
    "    \"num_file_creations\", \"num_shells\", \"num_access_files\", \"num_outbound_cmds\",\n",
    "    \"count\", \"srv_count\", \"serror_rate\", \"srv_serror_rate\", \"rerror_rate\",\n",
    "    \"srv_rerror_rate\", \"same_srv_rate\", \"diff_srv_rate\", \"srv_diff_host_rate\",\n",
    "    \"dst_host_count\", \"dst_host_srv_count\", \"dst_host_same_srv_rate\",\n",
    "    \"dst_host_diff_srv_rate\", \"dst_host_same_src_port_rate\", \"dst_host_srv_diff_host_rate\",\n",
    "    \"dst_host_serror_rate\", \"dst_host_srv_serror_rate\", \"dst_host_rerror_rate\",\n",
    "    \"dst_host_srv_rerror_rate\"]\n",
    "\n",
    "df[continuous_columns]=df[continuous_columns].apply(pd.to_numeric, errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44858b05",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "44858b05",
    "outputId": "4f8c874e-ccb5-438c-bd91-745ce103b23a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(494021, 42)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15c59412",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "15c59412",
    "outputId": "3d4e1b60-2e05-4600-8ec2-57683d64f89d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "duration                         int64\n",
       "protocol_type                   object\n",
       "service                         object\n",
       "flag                            object\n",
       "src_bytes                        int64\n",
       "dst_bytes                        int64\n",
       "land                            object\n",
       "wrong_fragment                   int64\n",
       "urgent                           int64\n",
       "hot                              int64\n",
       "num_failed_logins                int64\n",
       "logged_in                       object\n",
       "num_compromised                  int64\n",
       "root_shell                       int64\n",
       "su_attempted                     int64\n",
       "num_root                         int64\n",
       "num_file_creations               int64\n",
       "num_shells                       int64\n",
       "num_access_files                 int64\n",
       "num_outbound_cmds                int64\n",
       "is_host_login                   object\n",
       "is_guest_login                  object\n",
       "count                            int64\n",
       "srv_count                        int64\n",
       "serror_rate                    float64\n",
       "srv_serror_rate                float64\n",
       "rerror_rate                    float64\n",
       "srv_rerror_rate                float64\n",
       "same_srv_rate                  float64\n",
       "diff_srv_rate                  float64\n",
       "srv_diff_host_rate             float64\n",
       "dst_host_count                   int64\n",
       "dst_host_srv_count               int64\n",
       "dst_host_same_srv_rate         float64\n",
       "dst_host_diff_srv_rate         float64\n",
       "dst_host_same_src_port_rate    float64\n",
       "dst_host_srv_diff_host_rate    float64\n",
       "dst_host_serror_rate           float64\n",
       "dst_host_srv_serror_rate       float64\n",
       "dst_host_rerror_rate           float64\n",
       "dst_host_srv_rerror_rate       float64\n",
       "target                          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86df1b40",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "86df1b40",
    "outputId": "baf28733-f872-4261-dd12-968e20791e36"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshu\\AppData\\Local\\Temp\\ipykernel_6876\\1323211320.py:27: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[\"target\"]=df[\"target\"].replace(target_mapping)\n"
     ]
    }
   ],
   "source": [
    "df[\"target\"]=df[\"target\"].str.decode(\"utf-8\")\n",
    "target_mapping={\n",
    "    \"smurf.\": 0,\n",
    "    \"neptune.\": 1,\n",
    "    \"normal.\": 2,\n",
    "    \"back.\": 3,\n",
    "    \"satan.\": 4,\n",
    "    \"ipsweep.\": 5,\n",
    "    \"portsweep.\": 6,\n",
    "    \"warezclient.\": 7,\n",
    "    \"teardrop.\": 8,\n",
    "    \"pod.\": 9,\n",
    "    \"nmap.\": 10,\n",
    "    \"guess_passwd.\": 11,\n",
    "    \"buffer_overflow.\": 12,\n",
    "    \"land.\": 13,\n",
    "    \"warezmaster.\": 14,\n",
    "    \"imap.\": 15,\n",
    "    \"rootkit.\": 16,\n",
    "    \"loadmodule.\": 17,\n",
    "    \"ftp_write.\": 18,\n",
    "    \"multihop.\": 19,\n",
    "    \"phf.\": 20,\n",
    "    \"perl.\": 21,\n",
    "    \"spy.\": 22}\n",
    "\n",
    "df[\"target\"]=df[\"target\"].replace(target_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "946c410b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "946c410b",
    "outputId": "589f5b43-e8aa-4a75-fd3f-c1350c3e28ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['protocol_type', 'service', 'flag', 'land', 'logged_in',\n",
      "       'is_host_login', 'is_guest_login'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "object_cols=df.select_dtypes(include=[\"object\"]).columns\n",
    "print(object_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68058367",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "68058367",
    "outputId": "a67be958-1108-4cec-9d0c-4d56fbb1d4b9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshu\\AppData\\Local\\Temp\\ipykernel_6876\\1407051850.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[\"land\"]=df[\"land\"].replace({0:0, 1:1})\n",
      "C:\\Users\\joshu\\AppData\\Local\\Temp\\ipykernel_6876\\1407051850.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[\"logged_in\"]=df[\"logged_in\"].replace({0:0, 1:1})\n",
      "C:\\Users\\joshu\\AppData\\Local\\Temp\\ipykernel_6876\\1407051850.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[\"is_host_login\"]=df[\"is_host_login\"].replace({0:0, 1:1})\n",
      "C:\\Users\\joshu\\AppData\\Local\\Temp\\ipykernel_6876\\1407051850.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[\"is_guest_login\"]=df[\"is_guest_login\"].replace({0:0, 1:1})\n",
      "C:\\Users\\joshu\\AppData\\Local\\Temp\\ipykernel_6876\\1407051850.py:25: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"protocol_type\"].replace(protocol_mapping, inplace=True)\n",
      "C:\\Users\\joshu\\AppData\\Local\\Temp\\ipykernel_6876\\1407051850.py:25: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[\"protocol_type\"].replace(protocol_mapping, inplace=True)\n",
      "C:\\Users\\joshu\\AppData\\Local\\Temp\\ipykernel_6876\\1407051850.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"service\"].replace(service_mapping, inplace=True)\n",
      "C:\\Users\\joshu\\AppData\\Local\\Temp\\ipykernel_6876\\1407051850.py:26: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[\"service\"].replace(service_mapping, inplace=True)\n",
      "C:\\Users\\joshu\\AppData\\Local\\Temp\\ipykernel_6876\\1407051850.py:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"flag\"].replace(flag_mapping, inplace=True)\n",
      "C:\\Users\\joshu\\AppData\\Local\\Temp\\ipykernel_6876\\1407051850.py:27: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[\"flag\"].replace(flag_mapping, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df[\"land\"]=df[\"land\"].replace({0:0, 1:1})\n",
    "df[\"logged_in\"]=df[\"logged_in\"].replace({0:0, 1:1})\n",
    "df[\"is_host_login\"]=df[\"is_host_login\"].replace({0:0, 1:1})\n",
    "df[\"is_guest_login\"]=df[\"is_guest_login\"].replace({0:0, 1:1})\n",
    "\n",
    "protocol_mapping={b'icmp':0, b'tcp':1, b'udp':2}\n",
    "\n",
    "service_mapping={b'ecr_i':0, b'private':1, b'http':2, b'smtp':3, b'other':4,\n",
    "    b'domain_u':5, b'ftp_data':6, b'eco_i':7, b'ftp':8, b'finger':9,\n",
    "    b'urp_i':10, b'telnet':11, b'ntp_u':12, b'auth':13, b'pop_3':14,\n",
    "    b'time':15, b'csnet_ns':16, b'remote_job':17, b'gopher':18, b'imap4':19,\n",
    "    b'discard':20, b'domain':21, b'iso_tsap':22, b'systat':23, b'shell':24,\n",
    "    b'echo':25, b'rje':26, b'whois':27, b'sql_net':28, b'printer':29,\n",
    "    b'nntp':30, b'courier':31, b'sunrpc':32, b'netbios_ssn':33, b'mtp':34,\n",
    "    b'vmnet':35, b'uucp_path':36, b'uucp':37, b'klogin':38, b'bgp':39,\n",
    "    b'ssh':40, b'supdup':41, b'nnsp':42, b'login':43, b'hostnames':44,\n",
    "    b'efs':45, b'daytime':46, b'link':47, b'netbios_ns':48, b'pop_2':49,\n",
    "    b'ldap':50, b'netbios_dgm':51, b'exec':52, b'http_443':53, b'kshell':54,\n",
    "    b'name':55, b'ctf':56, b'netstat':57, b'Z39_50':58, b'IRC':59,\n",
    "    b'urh_i':60, b'X11':61, b'tim_i':62, b'pm_dump':63, b'tftp_u':64, b'red_i':65}\n",
    "\n",
    "flag_mapping={b'SF':0, b'S0':1, b'REJ':2, b'RSTR':3, b'RSTO':4, b'SH':5, b'S1':6, b'S2':7,\n",
    "              b'RSTOS0':8, b'S3':9, b'OTH':10}\n",
    "\n",
    "df[\"protocol_type\"].replace(protocol_mapping, inplace=True)\n",
    "df[\"service\"].replace(service_mapping, inplace=True)\n",
    "df[\"flag\"].replace(flag_mapping, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15812cfe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "15812cfe",
    "outputId": "934d95a2-9503-4dde-fa3a-21c564889a07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "duration                         int64\n",
       "protocol_type                    int64\n",
       "service                          int64\n",
       "flag                             int64\n",
       "src_bytes                        int64\n",
       "dst_bytes                        int64\n",
       "land                             int64\n",
       "wrong_fragment                   int64\n",
       "urgent                           int64\n",
       "hot                              int64\n",
       "num_failed_logins                int64\n",
       "logged_in                        int64\n",
       "num_compromised                  int64\n",
       "root_shell                       int64\n",
       "su_attempted                     int64\n",
       "num_root                         int64\n",
       "num_file_creations               int64\n",
       "num_shells                       int64\n",
       "num_access_files                 int64\n",
       "num_outbound_cmds                int64\n",
       "is_host_login                    int64\n",
       "is_guest_login                   int64\n",
       "count                            int64\n",
       "srv_count                        int64\n",
       "serror_rate                    float64\n",
       "srv_serror_rate                float64\n",
       "rerror_rate                    float64\n",
       "srv_rerror_rate                float64\n",
       "same_srv_rate                  float64\n",
       "diff_srv_rate                  float64\n",
       "srv_diff_host_rate             float64\n",
       "dst_host_count                   int64\n",
       "dst_host_srv_count               int64\n",
       "dst_host_same_srv_rate         float64\n",
       "dst_host_diff_srv_rate         float64\n",
       "dst_host_same_src_port_rate    float64\n",
       "dst_host_srv_diff_host_rate    float64\n",
       "dst_host_serror_rate           float64\n",
       "dst_host_srv_serror_rate       float64\n",
       "dst_host_rerror_rate           float64\n",
       "dst_host_srv_rerror_rate       float64\n",
       "target                           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffade053",
   "metadata": {
    "id": "ffade053"
   },
   "source": [
    "Must Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20d81d21",
   "metadata": {
    "id": "20d81d21"
   },
   "outputs": [],
   "source": [
    "X=df.drop(columns=[\"target\"], axis=1)\n",
    "y=df[\"target\"]\n",
    "\n",
    "X_train, X_temp, y_train, y_temp=train_test_split(X, y, test_size=0.3, random_state=11)\n",
    "X_val, X_test, y_val, y_test=train_test_split(X_temp, y_temp, test_size=0.5, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0028ca60",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0028ca60",
    "outputId": "4899826b-4bd1-4bfc-e695-207d1d939b4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Logistic Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joshu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joshu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joshu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joshu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joshu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joshu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.998475095475217\n",
      "\n",
      "Training Random Forest...\n",
      "Model Accuracy: 0.9998245685059984\n",
      "\n",
      "Training SVM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.9995546738998421\n"
     ]
    }
   ],
   "source": [
    "def Classifiers(pipeline, param_grid, X_train, y_train, X_val, y_val):\n",
    "    \n",
    "    Grid = GridSearchCV(pipeline, param_grid, cv = 3, scoring = \"accuracy\")\n",
    "    Grid.fit(X_train, y_train)\n",
    "    top_model = Grid.best_estimator_\n",
    "    y_val_pred = top_model.predict(X_val)\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    print(f\"Model Accuracy: {accuracy}\")\n",
    "    return top_model\n",
    "\n",
    "classifiers = {\"Logistic Regression\": LogisticRegression(), \"Random Forest\": RandomForestClassifier(),\n",
    "    \"SVM\": SVC()}\n",
    "\n",
    "parameters = {\n",
    "    \"Logistic Regression\": {\"classifier__C\": [0.1, 1, 10], \"classifier__solver\": [\"liblinear\"]},\n",
    "    \"Random Forest\": {\"classifier__n_estimators\": [100, 200], \"classifier__max_depth\": [10, 20, None]},\n",
    "    \"SVM\": {\"classifier__C\": [0.1, 1, 10], \"classifier__kernel\": [\"linear\", \"rbf\"]}}\n",
    "\n",
    "classifier = {}\n",
    "for name, clf in classifiers.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    pipeline = Pipeline([(\"scaler\", StandardScaler()),(\"classifier\", clf)])\n",
    "    top_model = Classifiers(pipeline, parameters[name], X_train, y_train, X_val, y_val)\n",
    "    classifiers[name] = top_model\n",
    "\n",
    "for name, model in classifier.items():\n",
    "    Y_Test_Prediction = model.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, Y_Test_Prediction)\n",
    "    print(f\"Accuracy of {name}: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45953479",
   "metadata": {},
   "source": [
    "Random forest performed better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-wTzV79PluVz",
   "metadata": {
    "id": "-wTzV79PluVz"
   },
   "source": [
    "# Exercise 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d457a08",
   "metadata": {
    "id": "4d457a08"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_Train_Scaled = scaler.fit_transform(X_train)\n",
    "X_Value_Scaled = scaler.transform(X_val)\n",
    "X_Test_Scaled = scaler.transform(X_test)\n",
    "N = 25\n",
    "Models = []\n",
    "Predictions = np.zeros((X_Value_Scaled.shape[0], N, len(np.unique(y))))\n",
    "\n",
    "for i in range(N):\n",
    "    Model = RandomForestClassifier(n_estimators = 100, random_state = i)\n",
    "    Model.fit(X_Train_Scaled, y_train)\n",
    "    Models.append(Model)\n",
    "    Predictions[:, i, :] = Model.predict_proba(X_Value_Scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ZKEvawtUxmTL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZKEvawtUxmTL",
    "outputId": "afb8a65d-0c46-48af-a262-f9c446da30dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10% Uncertainty of Data: 74103\n",
      "Bottom 10% Uncertainty of Data: 71900\n"
     ]
    }
   ],
   "source": [
    "def Entropy_of_Predictions(Predictions):\n",
    "    \n",
    "    Probability = np.mean(Predictions, axis=1)\n",
    "    Entropy = -np.sum(Probability*np.log(Probability+1e-10), axis=1)\n",
    "    return Entropy\n",
    "\n",
    "Uncertainty = Entropy_of_Predictions(Predictions)\n",
    "Top_10_Percent  = np.percentile(Uncertainty, 90)\n",
    "Bottom_10_Percent = np.percentile(Uncertainty, 10)\n",
    "Top_Uncertainty = np.where(Uncertainty >= Top_10_Percent)[0] \n",
    "Bottom_Uncertainty = np.where(Uncertainty <= Bottom_10_Percent)[0]\n",
    "Top_Uncertainty1 = X_Value_Scaled[Top_Uncertainty]\n",
    "Bottom_Uncertainty1 = X_Value_Scaled[Bottom_Uncertainty]\n",
    "\n",
    "print(f'Top 10% Uncertainty of Data: {Top_Uncertainty1.shape[0]}')\n",
    "print(f'Bottom 10% Uncertainty of Data: {Bottom_Uncertainty1.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i9ZnQRSpxv-8",
   "metadata": {
    "id": "i9ZnQRSpxv-8"
   },
   "source": [
    "# Exercise 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "MrmxUTT4x1Un",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MrmxUTT4x1Un",
    "outputId": "ab66a969-fe5d-42e3-ebea-9fa5f581445f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Features with the Random Forest Estimator Model:\n",
      "Index(['protocol_type', 'service', 'flag', 'src_bytes', 'count', 'srv_count',\n",
      "       'same_srv_rate', 'diff_srv_rate', 'dst_host_same_srv_rate',\n",
      "       'dst_host_same_src_port_rate'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "Random_Forest_Classifier = RandomForestClassifier(n_estimators = 100, random_state = 11)\n",
    "Random_forest_Estimator = RFE(estimator = Random_Forest_Classifier, n_features_to_select = 10)\n",
    "Random_forest_Estimator.fit(X_train, y_train)\n",
    "Random_forest_Estimator_Support = Random_forest_Estimator.support_\n",
    "Random_forest_Estimator_Features = X.columns[Random_forest_Estimator_Support]\n",
    "\n",
    "print(\"Top 10 Features with the Random Forest Estimator Model:\")\n",
    "print(Random_forest_Estimator_Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ift9Tp13x16m",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ift9Tp13x16m",
    "outputId": "c656bf33-7f15-4eb1-a6f0-aa990e328b21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Features using Select From Model:\n",
      "Index(['protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes',\n",
      "       'logged_in', 'count', 'srv_count', 'srv_serror_rate', 'same_srv_rate',\n",
      "       'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count',\n",
      "       'dst_host_srv_count', 'dst_host_same_srv_rate',\n",
      "       'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
      "       'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',\n",
      "       'dst_host_srv_serror_rate', 'dst_host_rerror_rate'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\joshu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "Random_Forest_Classifier.fit(X_train, y_train)\n",
    "Model = SelectFromModel(Random_Forest_Classifier, prefit = True, threshold = \"median\")\n",
    "X_Train_Selected = Model.transform(X_train)\n",
    "X_Value_Selected = Model.transform(X_val)\n",
    "Feature_Indices = Model.get_support(indices = True)\n",
    "Feature_Names = X.columns[Feature_Indices]\n",
    "\n",
    "print(\"Top 10 Features using Select From Model:\")\n",
    "print(Feature_Names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "HHzmoAEsx19O",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HHzmoAEsx19O",
    "outputId": "681daad2-40ec-48eb-9d29-39d690875186"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Top Features: 0.9998515579666141\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     42026\n",
      "           1       1.00      1.00      1.00     16233\n",
      "           2       1.00      1.00      1.00     14538\n",
      "           3       1.00      1.00      1.00       341\n",
      "           4       1.00      1.00      1.00       240\n",
      "           5       0.99      1.00      1.00       176\n",
      "           6       1.00      1.00      1.00       156\n",
      "           7       1.00      0.99      1.00       163\n",
      "           8       1.00      1.00      1.00       134\n",
      "           9       0.97      1.00      0.99        35\n",
      "          10       1.00      0.97      0.99        35\n",
      "          11       1.00      1.00      1.00         9\n",
      "          12       0.83      1.00      0.91         5\n",
      "          13       1.00      1.00      1.00         2\n",
      "          14       0.67      1.00      0.80         2\n",
      "          15       1.00      1.00      1.00         2\n",
      "          17       0.00      0.00      0.00         2\n",
      "          18       0.00      0.00      0.00         2\n",
      "          19       0.00      0.00      0.00         1\n",
      "          21       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           1.00     74103\n",
      "   macro avg       0.77      0.80      0.78     74103\n",
      "weighted avg       1.00      1.00      1.00     74103\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\joshu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\joshu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "Features = np.unique(np.concatenate((Random_forest_Estimator_Features, Feature_Names)))\n",
    "X_Train_Features = X_train.loc[:, np.isin(X.columns, Features)]\n",
    "X_Value_Features = X_val.loc[:, np.isin(X.columns, Features)]\n",
    "X_Test_Features = X_test.loc[:, np.isin(X.columns, Features)]\n",
    "Random_Forest_Classifier_Features = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "Random_Forest_Classifier_Features.fit(X_Train_Features, y_train)\n",
    "Y_Value_Predicted_Features = Random_Forest_Classifier_Features.predict(X_Value_Features)\n",
    "\n",
    "print(f\"Accuracy with Top Features: {accuracy_score(y_val, Y_Value_Predicted_Features)}\")\n",
    "print(classification_report(y_val, Y_Value_Predicted_Features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde05900",
   "metadata": {},
   "source": [
    "From the previous question random forest performed at 0.99982 while here it performs at 0.99985 accuracy. Which is much better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "irJ8ceqY1MxB",
   "metadata": {
    "id": "irJ8ceqY1MxB"
   },
   "source": [
    "# Exercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "jLyeVDpzx2AA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "jLyeVDpzx2AA",
    "outputId": "14041678-da59-4d6b-cdaf-2d0d1a7c1383"
   },
   "outputs": [],
   "source": [
    "# K-Means Clustering\n",
    "K_Means_Clustering = KMeans(n_clusters = 3, random_state = 1)\n",
    "K_Means_Clusters = K_Means_Clustering.fit_predict(X_Train_Scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "VKc8Fncespi3",
   "metadata": {
    "id": "VKc8Fncespi3"
   },
   "outputs": [],
   "source": [
    "#Gaussian Mixture\n",
    "Gaussian_Mixture=GaussianMixture(n_components = 3, random_state = 11)\n",
    "Gaussian_Mixture_Clusters= Gaussian_Mixture.fit_predict(X_Train_Scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YDHy62XQsppo",
   "metadata": {
    "id": "YDHy62XQsppo"
   },
   "outputs": [],
   "source": [
    "#Density-Based Clustering\n",
    "Density_Based_Clustering = DBSCAN(eps=1, min_samples=10)\n",
    "Density_Based_Clusters = Density_Based_Clustering.fit_predict(X_Train_Scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf74939",
   "metadata": {
    "id": "Ka1khLDXtt9a"
   },
   "outputs": [],
   "source": [
    "K_Means_Score = silhouette_score(X_Train_Scaled, K_Means_Clusters)\n",
    "Gaussian_Score = silhouette_score(X_Train_Scaled, Gaussian_Mixture_Clusters)\n",
    "Density_Score = silhouette_score(X_Train_Scaled[dbscan_clusters != -1], Density_Based_Clusters[Density_Based_Clusters != -1])\n",
    "\n",
    "print(f'Silhouette Score for K-Means: {K_Means_Score:.4f}')\n",
    "print(f'Silhouette Score for Gaussian Mixture Models (GMM): {Gaussian_Score:.4f}')\n",
    "print(f'Silhouette Score for DBSCAN: {Density_Score:.4f}')\n",
    "\n",
    "def plot_clusters(X, clusters, title):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=clusters, cmap=\"viridis\", alpha=0.5)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Feature 1\")\n",
    "    plt.ylabel(\"Feature 2\")\n",
    "    plt.colorbar(label=\"Cluster Label\")\n",
    "    plt.show()\n",
    "\n",
    "plot_clusters(X_Train_Scaled, K_Means_Clusters, \"K-Means Clustering\")\n",
    "plot_clusters(X_Train_Scaled, Gaussian_Mixture_Clusters, \"Gaussian Mixture Clustering\")\n",
    "plot_clusters(X_Train_Scaled, Density_Based_Clusters, \"Density Based Clustering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d307d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(X_train)\n",
    "results[\"True Label\"] = y_train.values\n",
    "results[\"K-Means Cluster\"] = K_Means_Clusters\n",
    "results[\"Gaussian Mixture Cluster\"] = Gaussian_Mixture_Clusters\n",
    "results[\"Density Based Cluster\"] = Density_Based_Clusters\n",
    "\n",
    "print(\"\\nK-Means Clustering vs True Labels:\")\n",
    "print(results.groupby([\"True Label\", \"K-Means Cluster\"]).size())\n",
    "print(\"\\nGaussian Mixture Clustering vs True Labels:\")\n",
    "print(results.groupby([\"True Label\", \"Gaussian Mixture Clustering\"]).size())\n",
    "print(\"\\nDensity Based Clustering vs True Labels:\")\n",
    "print(results.groupby([\"True Label\", \"Density Based Clustering\"]).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fa2d0a",
   "metadata": {},
   "source": [
    "It kept failing here, it keeps making the kernel fail and restart regardless of what other clustering algorithm i use, it takes over 4 hours for it to get here each try, from my laptop, to my desktop, to google colab. Tried this for 3 weeks straight, and it black screened my computer 5 times, i dont want to brick my desktop or laptop. Data set is just too huge. Please use a smaller data set for the next poor souls trying to do this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78c93ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b04dfe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fed6290",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef4ed16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4269aef9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd403022",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd0c616",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
